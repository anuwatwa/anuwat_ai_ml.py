"""
Foundation Volume & Formwork Prediction Model (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß)
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ Volume of Concrete ‡πÅ‡∏•‡∏∞ Formwork ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ê‡∏≤‡∏ô‡∏£‡∏≤‡∏Å

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:
1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries: pip install pandas openpyxl scikit-learn numpy
2. ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Python ‡∏ô‡∏µ‡πâ
3. ‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î: python foundation_ml.py
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pickle
import warnings
warnings.filterwarnings('ignore')

# ========================================
# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ========================================
def load_and_clean_excel(file_path):
    """‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    print(f"\nüìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {file_path}")
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î header ‡∏Å‡πà‡∏≠‡∏ô
    df_raw = pd.read_excel(file_path, header=None)
    
    # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô header ‡∏à‡∏£‡∏¥‡∏á (‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ Type, Width, Length, etc.)
    header_row = None
    for idx, row in df_raw.iterrows():
        row_str = ' '.join([str(x) for x in row if pd.notna(x)])
        if 'Type' in row_str or 'Width' in row_str or 'Count' in row_str:
            header_row = idx
            break
    
    if header_row is None:
        print("  ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö header ‡πÉ‡∏ä‡πâ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô header")
        header_row = 0
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ header ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    df = pd.read_excel(file_path, header=header_row)
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    df = df.dropna(how='all')
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    df = df.dropna(axis=1, how='all')
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô header ‡∏ã‡πâ‡∏≥
    df = df[df.iloc[:, 0] != 'Type']
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    df.columns = df.columns.str.strip()
    
    print(f"  ‚úì ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    print(f"  ‚úì ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {df.columns.tolist()[:5]}...")
    
    return df

def combine_all_files():
    """‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    files = [
        '1.0 Foundation ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ê‡∏≤‡∏ô‡∏£‡∏≤‡∏Å.xlsx',
        '1.1 Foundation ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ê‡∏≤‡∏ô‡∏£‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡πÄ‡∏°‡∏ï‡∏£.xlsx',
        '1.2 Foundation ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ê‡∏≤‡∏ô‡∏£‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡πÄ‡∏°‡∏ï‡∏£.xlsx'
    ]
    
    all_data = []
    for file in files:
        try:
            df = load_and_clean_excel(file)
            all_data.append(df)
        except Exception as e:
            print(f"  ‚úó ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
    
    if not all_data:
        raise Exception("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    combined = pd.concat(all_data, ignore_index=True)
    print(f"\n‚úÖ ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(combined)} ‡πÅ‡∏ñ‡∏ß")
    
    return combined

# ========================================
# 2. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ========================================
def clean_numeric_column(series):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏•‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏≠‡∏≠‡∏Å)"""
    if series.dtype == 'object':
        # ‡∏•‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô 'm', 'm2', 'm3', 'kg'
        series = series.astype(str).str.replace(r'[^\d.-]', '', regex=True)
        series = pd.to_numeric(series, errors='coerce')
    return series

def prepare_data(df):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
    print("\n" + "="*70)
    print("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    print("="*70)
    
    print(f"\n‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ({len(df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i}. {col}")
    
    print("\n‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 3 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å:")
    print(df.head(3).to_string())
    
    # ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô features ‡πÅ‡∏•‡∏∞ targets
    feature_mapping = {
        'width': ['Width', '‡∏Å‡∏ß‡πâ‡∏≤‡∏á', 'W'],
        'length': ['Length', '‡∏¢‡∏≤‡∏ß', 'L'],
        'thickness': ['Thickness', '‡∏´‡∏ô‡∏≤', 'Thk', 'Thick', 'T'],
        'area': ['Area', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà'],
        'perimeter': ['Perimeter', '‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏≠‡∏ö‡∏£‡∏π‡∏õ'],
        'count': ['Count', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô', 'Qty']
    }
    
    target_mapping = {
        'volume': ['Volume', '‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ï‡∏£', 'Concrete', '‡∏Ñ‡∏≠‡∏ô‡∏Å‡∏£‡∏µ‡∏ï', 'Vol'],
        'formwork': ['Formwork', '‡πÅ‡∏ö‡∏ö‡∏´‡∏•‡πà‡∏≠', 'Form'],
        'steel': ['Steel', '‡πÄ‡∏´‡∏•‡πá‡∏Å', 'Rebar']
    }
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö features
    feature_cols = []
    used_columns = set()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
    
    for feature_type, keywords in feature_mapping.items():
        for col in df.columns:
            if col in used_columns:  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
                continue
            col_lower = col.lower()
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Type ‡πÄ‡∏õ‡πá‡∏ô Thickness
            if feature_type == 'thickness' and col_lower == 'type':
                continue
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Count ‡πÄ‡∏õ‡πá‡∏ô Thickness
            if feature_type == 'thickness' and col_lower == 'count':
                continue
            if any(kw.lower() in col_lower for kw in keywords):
                feature_cols.append(col)
                used_columns.add(col)
                print(f"  ‚úì ‡∏û‡∏ö {feature_type}: {col}")
                break
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö targets
    target_volume = None
    target_formwork = None
    target_steel = None
    
    for col in df.columns:
        col_lower = col.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Volume (‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ m3)
        if target_volume is None:
            for kw in target_mapping['volume']:
                if kw.lower() in col_lower:
                    target_volume = col
                    print(f"  ‚úì ‡∏û‡∏ö Volume: {col}")
                    break
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Formwork (‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ m2)
        if target_formwork is None:
            for kw in target_mapping['formwork']:
                if kw.lower() in col_lower:
                    target_formwork = col
                    print(f"  ‚úì ‡∏û‡∏ö Formwork: {col}")
                    break
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Steel
        if target_steel is None:
            for kw in target_mapping['steel']:
                if kw.lower() in col_lower:
                    target_steel = col
                    print(f"  ‚úì ‡∏û‡∏ö Steel: {col}")
                    break
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    print("\nüßπ ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    for col in feature_cols + [c for c in [target_volume, target_formwork, target_steel] if c]:
        if col in df.columns:
            df[col] = clean_numeric_column(df[col])
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    important_cols = [c for c in feature_cols + [target_volume, target_formwork] if c]
    if important_cols:
        before_clean = len(df)
        df = df.dropna(subset=important_cols, how='any')
        print(f"‚úì ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ NaN: {before_clean - len(df)} ‡πÅ‡∏ñ‡∏ß")
        print(f"‚úì ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    else:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    
    return df, feature_cols, target_volume, target_formwork, target_steel

# ========================================
# 3. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ========================================
def train_model(df, feature_cols, target_col, model_name):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ML"""
    if target_col is None or target_col not in df.columns:
        print(f"\n‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô {model_name} (‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)")
        return None, None, None
    
    print(f"\n{'='*70}")
    print(f"ü§ñ ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
    print(f"{'='*70}")
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    X = df[feature_cols].copy()
    y = df[target_col].copy()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    valid_mask = ~(X.isnull().any(axis=1) | y.isnull())
    X = X[valid_mask]
    y = y[valid_mask]
    
    print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(X)} ‡πÅ‡∏ñ‡∏ß")
    print(f"üìä Features: {X.columns.tolist()}")
    print(f"üìä Target range: {y.min():.2f} - {y.max():.2f}")
    
    if len(X) < 5:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 5 ‡πÅ‡∏ñ‡∏ß)")
        return None, None, None
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    if len(X) < 10:
        test_size = 0.1
    else:
        test_size = 0.2
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    # Standardize
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
    models = {
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=50, random_state=42, max_depth=3),
        'Linear Regression': LinearRegression()
    }
    
    best_model = None
    best_score = -np.inf
    best_name = ""
    
    print("\nüìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
    for name, model in models.items():
        try:
            if name == 'Linear Regression':
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
            
            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            
            print(f"\n  {name}:")
            print(f"    R¬≤ Score: {r2:.4f}")
            print(f"    MAE: {mae:.4f}")
            print(f"    RMSE: {rmse:.4f}")
            
            if r2 > best_score:
                best_score = r2
                best_model = model
                best_name = name
        except Exception as e:
            print(f"  ‚ö†Ô∏è {name} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
    
    if best_model:
        print(f"\n‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ: {best_name} (R¬≤ = {best_score:.4f})")
    
    return best_model, scaler, X.columns.tolist()

# ========================================
# 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ========================================
def save_model(model, scaler, feature_names, filename):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    if model is None:
        return
    
    model_data = {
        'model': model,
        'scaler': scaler,
        'feature_names': feature_names
    }
    
    with open(filename, 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {filename}")

def load_and_predict(model_file, input_data):
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢"""
    with open(model_file, 'rb') as f:
        data = pickle.load(f)
    
    model = data['model']
    scaler = data['scaler']
    features = data['feature_names']
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° input
    X = pd.DataFrame([input_data])[features]
    
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    if isinstance(model, LinearRegression):
        X = scaler.transform(X)
    
    return model.predict(X)[0]

# ========================================
# MAIN
# ========================================
if __name__ == "__main__":
    print("\n" + "="*70)
    print(" üèóÔ∏è  Foundation ML Model Training ")
    print("="*70)
    
    try:
        # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df = combine_all_files()
        
        # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df, features, vol_col, form_col, steel_col = prepare_data(df)
        
        if not features:
            print("\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
            print("üìã ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: Width, Length, Thickness, Area, Perimeter")
            exit(1)
        
        # 3. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Volume
        vol_model, vol_scaler, vol_features = train_model(df, features, vol_col, "Volume")
        if vol_model:
            save_model(vol_model, vol_scaler, vol_features, 'foundation_volume_model.pkl')
        
        # 4. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Formwork
        form_model, form_scaler, form_features = train_model(df, features, form_col, "Formwork")
        if form_model:
            save_model(form_model, form_scaler, form_features, 'foundation_formwork_model.pkl')
        
        # 5. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Steel
        steel_model, steel_scaler, steel_features = train_model(df, features, steel_col, "Steel")
        if steel_model:
            save_model(steel_model, steel_scaler, steel_features, 'foundation_steel_model.pkl')
        
        print("\n" + "="*70)
        print(" ‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ")
        print("="*70)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        if vol_model or form_model:
            print("\nüìù ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:")
            print("-" * 70)
            print("from foundation_ml import load_and_predict")
            print()
            print("# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input")
            print("data = {")
            for feat in features:
                print(f"    '{feat}': 1.5,  # ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á")
            print("}")
            print()
            if vol_model:
                print("volume = load_and_predict('foundation_volume_model.pkl', data)")
                print("print(f'Volume: {volume:.2f} m¬≥')")
            if form_model:
                print("formwork = load_and_predict('foundation_formwork_model.pkl', data)")
                print("print(f'Formwork: {formwork:.2f} m¬≤')")
        
    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        import traceback
        traceback.print_exc()